# CiRL

This repository contains the source code of the paper: Zocco, F., Corti, A. and Malvezzi, M., 2025. CiRL: Open-source environments for reinforcement learning in circular economy and 
net zero. arXiv preprint arXiv:2505.21536. 

The repository is divided into folders; each folder refers to a thermodynamic compartment and contains the Python notebooks with the training results reported in the above-mentioned paper.

GitHub may not be able to render the .ipynb files when you click on them. To visualize the .ipynb without issues, download and upload them to __Google Colaboratory__.

Note that the files named _envName_createAndTestEnvironment.ipynb_ with "envName" indicating the name of the compartment, implement the environment without any RL agent. This was needed to tune the integration step of the Euler's method for solving the differential equations numerically. The numerical simulation generated by these files was then compared with the one produced by the Python solver _scipy.integrate.odeint()_ for the same initial conditions and the same control input (i.e., the action). The .py files are the solution of the differential equations via _scipy.integrate.odeint()_. Once the integration step was tuned, the environment was ready to be combined with an RL algorithm.

